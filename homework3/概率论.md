# 第一 随机事件与概率
## 1.1 随机事件及其运算
### 随机现象，样本空间，随机事件，随机变量等，它们的概念和符号表示
* **随机现象**就是一定条件下并不总是出现相同结果的现象，只有一个结果的现象也可以叫确定性现象。对相同条件下的可以重复的随机现象的观察记录称为**随机试验**。
* 随机现象的一切可能基本结果组成的集合称为**样本空间**，记作$pass$,其中$pass$表示**基本结果**，又称为**样本点**。
    * 需要注意的是，样本空间中的元素可以是数也可以不是数。
    * 一个随机现象的样本空间至少有两个样本点。如果算上确定性现象，那么只有一个样本点的空间就是确定性现象的样本空间。
    * 样本空间有有限和无限的，无限的又有可数和不可数的。有限与可数的称为**离散样本空间**，不可数的称为**连续样本空间**
* 随机事件 
    * 随机变量的某些基本集合组成的结果称为**随机事件**，简称**事件**，常用大写字母A，B，C等表示。
    * 如"掷骰子掷出奇数点"，是一个事件，记为A，则有$A=\{1,3,5\}$
    * 所以说概率论有下面的特征：
        * 任一事件A是相应的基本空间$\Omega$中的一个子集，在概率论中常用一个大长方形示意基本空间$\Omega$，用一个圆或者其他的几何图形来示意，这叫做Venn图。
        * 事件A发生当且仅当事件A中的某一基本结果发生
    * 必然事件和不可能事件，略

* 随机变量
    * 用来表示随机现象结果的变量就是**随机变量**，常用大写字母X，Y，Z表示。表示时应该写明随机变量的含义。
    * 通过不同的设定可以产生不同的随机变量，以掷一枚骰子为例：
        * 设出现的点数为随机变量，X=1，2，3，4，5，6
        * “出现6”和“没有出现6”，X=1，0
        * 掷出奇数，X=1，0

### 事件间的关系和运算，它们的性质
* 事件间的关系：
    * 包含：如果属于A的样本点必属于B，则说B包含A，记作$A\subset B$或$B\supset A$.
        * 用概率论的语言说，也就是A发生是B必然发生
    * 相等： 如果属于A的样本点必然属于B，属于B的样本点也必然属于A，则说A与B相等，记作A=B
    * 互不相容：如果A与B没有相同的样本点，则成A与B互不相容。
        * 也就是说，A与B一定不可能同时发生。
* 运算
    * 并：取两个事件中所有的样本点组成的新事件，记作$A\cup B$
        * 可以推广到有限个或可数个事件的并
    * 交: 取两个事件中都有的样本点组成的新事件，记作$A\cap B$或AB
        * 可以推广到有限个或可数个事件的交
    * 差: 由在A中而不在B中的样本点组成的新事件，记作$A-B$
    * 对立: 事件A的对立事件指的是在$\Omega$中而不在A中的所有事件，记作$\overline{A}$
* 事件运算的性质
    1. 交换律：并和交都有交换律
    2. 结合律：并和交都有结合律
    3. 分配律：并和交互相对对方有分配律
    4. 德摩根律：事件的并的对立等于事件的对立的交，事件的交的对立等于事件的对立的并,可以推广到可数个事件。

### 事件域
* 事件域就是一个样本空间中某些子集及其运算结果而组成的集合类。记作$\Gamma$。这里的“某些子集”可以是全体子集。
    * 对于离散的情况，所有子集的全体就可以构成事件域
    * 对于连续的情况，子集中有零测集，这样的子集称为不可测集。我们只把可测子集看作事件。
* 设$\Omega$为一样本空间,$\mathfrak{\Gamma}$为$\Omega$的某些子集所组成的集合类，如果满足
    * $\Omega = \Gamma$
    * 如果$A \in \Gamma$则对立事件$A \in \Gamma$
    * 若$A_n \in \Gamma$则可列并$A \in \Gamma$  
    
    则称$\Gamma$是一个事件域，又称$\sigma$域或者$\sigma$代数.
    
* 在概率论中，又称$（\Omega,\Gamma）$为可测空间，在可测空间上才可以定义概率。
* 经过一些扩展操作之后得到的$\Gamma$称为博雷尔（Borel）事件域，域中的每一个元素（集合）又称为**博雷尔集**或**可测集**
* 样本空间的分割：如果对样本空间$\Omega$，存在N个事件$D_1,D_2,D_3,...,D_n$满足诸$D_i$互不相容且并集等于$\Omega$.则称为一组分割。分割很常用，因为可以化简被研究的问题。
    * 若分割有n个事件，则产生的事件域有$2^n$个不同的事件。

## 1.2 概率的定义及其确定方法
### 概率的公理化定义   
* 设$\Omega$为一个样本空间，$\Gamma$为$\Omega$的某些子集组成的一个事件域，如果对任意事件$A in \Gamma$，定义在$\Gamma$上的一个实值函数$P(A)$满足下面三条公理：
    * 非负性：P(A)>=0
    * 正则性: $P(\Omega)=1$
    * 可列可加性 : 可列个互不相容的事件的并的概率，等于他们的概率的和

* 称$P(A)$为事件A的概率,称三元组$(\Omega,\Gamma,P)$为概率空间

### 排列和组合
* 乘法原理：若一个事情有k个步骤组成，每一个步骤有$m_1,m_2,...,m_k$种方法，则完成整件事的方法总数是这些方法数量的乘积。
* 加法原理：若某件事情可以由k种方法之一完成，每一个途径有$m_1,m_2,...,m_k$种方法，则完成整件事的方法总数是这些方法数量的加和。
* 排列： 从n个不同元素中任取r个排成一列，考虑选取的顺序(r<=n)
    * $P^r_n = \frac{n!}{(n-r)!}$，对于r=n的情况称为全排列，全排列$P_n = n!$
* 重复排列： 从n个不同元素中拿取一个再放回，重复r次，考虑选取的顺序(r可以大于n)
    * $n^r$
* 组合： 从n个不同元素中任取r个的组合，不考虑选取的顺序(r<=n)
    * $C^r_n = \frac{n!}{r!(n-r)!}$
* 重复组合： 从n个不同元素中拿取一个再放回，重复r次，不考虑选取的顺序(r可以大于n)
    * $C^r_{n+r-1}$ ，显然$C^r_{n+r-1} = C^{n-1}_{n+r-1}$
 
### 确定概率的四大方法（频率，古典，几何，主观）
* 频率方法：
    * 如果考察事件A的随机现象可以大量重复进行，且进行不会影响到之后的结果，那么可以用频率的稳定值来获得概率。
    * n次重复实验后记n(A)为事件A出现的次数，又称n(A)为事件A的频数，称$f_n(A)=\frac{n(A)}{n}$为事件A出现的频率。

* 古典方法：
    * 随机事件只有有限个样本点，且每个样本点发生的可能性相等
    * 古典概型计算经常用到排列组合定律

* 几何方法：
    * 如果一个随机现象$\Omega$的样本空间充满某个区域，其度量的大小可以用$S_\Omega$表示
    * 任意一点落在度量相同的子区域内的可能性相等，不论子区域的形状和位置。
    * 若事件A为$\Omega$中的某个子区域，且其度量空间的大小可用$S_A$表示，则事件A的概率为$P(A)=\frac{S_A}{S_{\Omega}}$

* 主观方法：
    * 对于一些无法重复的事件，人们只能通过经验和主观信念来估计。
    * 如外科医生估计自己对下次手术的成功概率，企业家估计将要上市的新产品畅销的概率，人们根据今天的天气情况估计明天下雨的概率。
    * 主观概率也应该符合概率的公理化定义。

## 1.3 概率的性质
### 可加性和单调性
* 有限可加性，略
* 单调性，也就是说A包含B时，A发生的概率应当比B大，且A-B发生的概率就是A的概率与B的概率的差
* 显然反过来，也就是A发生的概率比B大，是不能推出A包含B的

### 加法公式
* 可加性：AB两事件的并的概率，相当于AB两事件的概率之和减去AB两事件的交的概率.可以推广到有限个事件的和
* 半可加性：任意两个事件的并的概率一定不大于两个事件的概率之和

### 连续性
* 略
* 由连续性和有限可加性，可以推出概率由可列可加性。

## 1.4 条件概率
### 定义
* 条件概率就是事件B发生的条件下另一个事件A发生的概率，记作$P(A|B)$。
* 设A与B是样本空间$\Omega$中的两事件，若P(B)>0，则称$P(A|B)=\frac{P(AB)}{P(B)}$为在B发生的条件下A发生的概率。
* 性质：条件概率是概率，符合概率的所有性质

### 乘法公式
* 若P(B)>0,则$P(AB)=P(B)P(A|B)$
* 若$P(A_1,A_2,...,A_{n-1})>0$,则
$$
    P(A_1,A_2,...,A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)...P(A_n|A_1A_2...A_{n-1})
$$

* 应用：罐子模型，不返回抽样，返回抽样，传染病模型，安全模型等

### 全概率公式
* 全概率公式提供了计算复杂概率的一条有效途径
* 设$B_1,B_2,...,B_n$为样本空间$\Omega$的一个分割，即所有的这些事件互不相容且其并为全集。如果每一个事件发生的概率P(B_i)均大于零，则对任意事件A有
$$P(A) = \sum_{i=1}^{n}P(B_i)P(A|B_i)$$
* 全概率公式的最简单形式：
    $$P(A)=P(B)P(A|B)+P(\overline{B})P(A|\overline{B})$$
* 只要A发生的概率被$B_1...B_i$全部包含，且这些是一个分割，全概率公式就成立
* 对于可列个事件组成的分割，全概率公式都成立。
* 应用：摸彩模型，敏感性问题调查

### 贝叶斯公式
* 不需要解释，人类的祖先已经把这个公式刻在DNA里，你也应该刻在脑子里面。
* 设$B_1,B_2,...,B_n$是样本空间$\Omega$的一个分割，如果$P(A)>0，P(B_i)>0,i=1,2,...,n$，则
$$ 
    P(B_i|A) = \frac{P(B_i)P(A|B_i)}{\sum^{n}_{j=1}P(B_j)P(A|B_j)} , i=1,2,...,n
$$
这个公式实际上就是条件概率的概率，对分子用乘法公式，对分母用全概率公式。
* 乘法概率是求事件交的概率，全概率公式是求一个复杂事件的概率，贝叶斯公式是求一个条件概率。
* 贝叶斯公式中如果称$P(B_i)$为$B_i$的先验概率，$P(B_i|A)$为$B_i$的后验概率，则贝叶斯公式是专门用于计算后验概率的，也就是说，通过事件A发生这个新信息对事件$B_i$发生概率做出的修正。

## 1.5 独立性
### 两个事件和多个事件的独立性
* 两个事件的独立性指的是一件事情的发生不影响另一件事情发生。也就是说有$P(A|B)=P(A)$和$P(A|B)=P(B)$,等价于$P(AB)=P(A)P(B)$。
* 若上式成立，则称事件A与B相互独立，简称A与B独立，否则称A与B不独立或相依。
* 类似的可以定义
$$
\left\{ \begin{array}{l}
    P(AB)=P(A)P(B) \\
    P(AC)=P(A)P(C) \\
    P(BC)=P(B)P(C)
\end{array} \right.
$$
称A,B,C三个事件两两独立，若还有
$$
P(ABC) = P(A)P(B)P(C)
$$
称A,B,C相互独立
* 类似的可以推广到n个事件，称个事件之间相互独立。
* N个相互独立的事件的一部分依然是相互独立的，将相互独立事件的一部分换为对立事件所得的几个事件依然是相互独立的。

### 试验的独立性
* 如果多次试验中每次试验的任一结果与其他试验的任一结果都是相互独立的事件，那么说这些试验相互独立。
* 如果每次试验是相同的，那么称为n重独立重复试验。如果每次试验的结果只有$A$或$\overline{A}$，那么称为伯努利试验。

## 附录：前面提到的应用模型
### 排列组合
* 抽样模型
* 放回抽样
* 盒子模型

### 条件概率
* 罐子模型
* 摸彩模型

# 第二 随机变量及其分布
## 2.1 随机变量及其分布
### 基本概念，分布函数
* 定义：定义在样本空间$\Omega$上的实值函数$X = X(\omega)$称为随机变量，常用大写字母X,Y,Z等表示随机变量，其取值用小写字母x,y,z表示。
    * 假如一个随机变量仅可能取有限个或可列个值，那么称为**离散型随机变量**
    * 如果能充满数轴上的一个区间(a,b)则称为**连续型随机变量**。其中的a和b可以是正负无穷。
* 也就是说，随机变量$X$是样本点$\omega$的一个函数。其自变量不一定是数，但因变量一定是数。
* 与微积分中的变量不同的是，随机变量伴随一个分布，也就是说我们需要知道取各个值的概率是多少。
* 随机变量是样本点$\omega$的一个实质函数，若B是某些数值组成的集合，即$B \sub R(实数集)$，则$X \in B$表示如下的随机事件：
$$
\{ \omega:X(\omega) \in B \} \sub Q
$$
用等号或不等号将随机变量与某些实数连接起来都可以表示随机事件。
* 设X是一个随机变量，对任何实数x,称
$$
F(x) = P (X \leq x)
$$
为随机变量X的**分布函数**，且称**X服从F(x)**，记作**X~F(X)**。有时也用$F_x(x)$以表明X的分布函数(把X写成F的下标)

* 任一随机变量X（离散的或者是连续的），都有一分布函数。有了分布函数，就可以据此算得与随机变量X有关的事件的概率。
* 分布函数有三条基本性质，这三条就是判断一个函数是否为分布函数的充要条件：
    * 单调性：F(x)是定义在整个实数轴上的单调非减函数
    * 有界性：对任意的x有$0 \leq F(x) \leq 1$且$F(- \infty) = lim_{x \to -\infty}F(x) = 0$,$F(\infty) = lim_{x \to \infty}F(x)=1$
    * 右连续性：$F(x_0+0) = F(x_0)$

### 离散随机变量的概率分布列，连续随机变量的概率密度函数
* 设X是一个离散随机变量，如果X的所有可能取值是$x_1,x_2,...,x_n,...$则称X取$x_i$的该概率
$$
p_i=p(x_i)=P(x=x_i),i=1,2,...,n,...
$$
为X的**分布列**或**概率分布列**，记作**x ~ {P}**.分布列也可以列表表示。
* 分布列的基本性质：
    * 非负性：也就是全部都是非负数
    * 正则性：也就是全部加起来等于1
* 设随机变量X的分布函数为F(x)，如果存在实数轴上的一个非负可积函数p(x)，使得对任意实数x有
$$
    F(x) = \int_{-\infty}^{x}p(t)dt
$$
则称p(x)为X的**概率密度函数**，简称**密度函数**或者**密度**。同时称X为**连续随机变量**，称F(x)为**连续分布函数**。
* 概率密度函数同样具有非负性和正则性。
* 如果分布列、概率密度函数中有一个待定常数，可以由正则型很容易得求出来。

## 2.2 随机变量的数学期望
### 数学期望的概念与定义
* 设离散随机变量X的分布列为
$$
p(x_i)=p(X=x_i),i=1,2,...,n,...
$$
如果
$$
\sum_{i=1}^{\infty}|x_i|p(x_i)< \infty
$$
则称
$$
E(x)=\sum_{i=1}^{\infty}x_ip(x_i)
$$
为随机变量X的**数学期望**，或成为该分布的数学期望，简称**期望**或者**均值**，若级数
$\sum_{i=1}^{\infty}|x_i|p(x_i)$不收敛，则称X的数学期望不存在。

* 要求级数绝对收敛的目的在于使其数学期望唯一，由于有限项和不受次序变动的影响，故取有限个可能值的随机变量的数学期望总是存在的。

* 对于连续的场合，只要将求和改为求积分即可：  
设连续随机变量X的密度函数为p(x)，如果
$$
\int_{-\infty}^{\infty}|x|p(x)dx<\infty
$$
则称
$$
E(x)=\int_{-\infty}^{\infty}xp(x)dx
$$
为X的**数学期望**，或成为该分布p(x)的数学期望，简称**期望**或**均值**。若
$\int_{-\infty}^{\infty}|x|p(x)dx<\infty$不收敛，则称X的数学期望不存在。

* 数学期望的物理意义是重心，也是消除随机性的重要手段。E(X)常作为X的分布的代表参与同类指标的比较。

### 数学期望的性质
* 若随机变量X的分布用分布列$p(x_i)$或者密度函数p(x)表示，则x的某一函数g(X)的数学期望为
$$
E[g(x)]=\left\{ \begin{array}{l}
   \sum_{i}g(x_i)p(x_i),在离散场合 \\
    \int_{-\infty}^{\infty}g(x)p(x)dx,在连续场合
\end{array} \right.
$$
这里假设所涉及的数学期望都假定存在。
* 若c是常数，则E(c)=c
* 任意常数a,有E(aX)=aE(X)
* 对于任意两个函数$g_1(x)$和$g_2(x)$，有
$$
E[g_1(x) \pm g_2(x)]=E[g_1(X)] \pm E[g_2(X)]
$$

## 2.3 随机变量的方差与标准差
### 方差和标准差的定义
* 若随机变量$X^2$的数学期望$E(X^2)$存在，则称偏差平方$(E-E(X))^2$的数学期望$E(X-E(X)^2)$为随机变量X（或相应分布）的**方差**，记作
$$
Var(X)=E(X-E(X))^2 = \left \{ \begin{array}{l}
    \sum_{i}(x_i-E(X))^2p(x_i),在离散场合\\
    \int_{-\infty}^{\infty}(x-E(X))^2,在连续场合\\
    \end{array} \right.
$$

* 称方差的正平方根$\sqrt{Var(X)}$为随机变量X(或相应分布)的标准差，记作$\sigma(x)$，或$\sigma_x$

* 方差和标准差都是描述随机变量的散布大小的特征数，主要差别在量纲上。标准差的量纲是与数学期望一致的，故$E(X) \pm k\sigma(X)$是有意义的，但标准差的计算必须通过方差。

* 如果随机变量X的数学期望存在，其方差可能不存在，而如果其方差存在，数学期望则一定存在。

### 方差的性质
假定以下随机变量的方差总是存在的：
* $Var(X)=E(X^2)-[E(X)]^2$
* 常数的方差为0,即Var(c)=0,其中c是常数
* 若a,b是常数，则$Var(aX+b)=a^2Var(X)$

### 切比雪夫不等式
* 设随机变量X的数学期望和方差都存在，则对任意常数$\epsilon>0$，有
$$
P(|X-E(X)|\geq \epsilon)\leq \frac{Var(X)}{\epsilon^2}
$$
或者
$$
P(|X-E(X)|<\epsilon) \geq 1- \frac{Var(X)}{\epsilon^2}
$$
* 在概率论中，事件$\{|X-E(X)|\geq\epsilon\}$称为**大偏差**，其概率$P(|X-E(X)|\geq \epsilon)$称为**大偏差发生概率**，切比雪夫不等式给出大偏差发生概率的上界，这个上界和方差成正比。
* 若随机变量X的方差存在，则Var(X)=0的充要条件是X几乎处处为某个常数a,即P(X=a)=1

## 2.4 常用离散分布
### 二项分布
记X为n重伯努利试验中成功（记为事件A）的次数，则X的可能取值为0,1,...，n,记p为每次试验中A发生的概率，即$P(A)=P$，则$P(\overline{A})=1-p$.
也就是N重伯努利试验中成功k次的概率，由独立性可知：$P(\omega)=p^k(1-p)^{n-k}，k = 1,2,...,n$，由于事件{x=k}中共有$C_n^k$个这样的$\omega$，所以X的分布列为：
$$
P（X=k）=C_n^k p^k (p-1)^{n-k} , k=1,2,...,n
$$
这个分布称为**二项分布**，记作X～b(n,p).  
这个数字恰好是n次二项式$(p+(1-p))^n$的展开式中的第k+1项，这正是其名称的由来。
二项分布是一种常用的离散分布，有如下例子：
* 检查10件产品，产品中不合格品的个数X服从二项分布b(10,p)，其中p为不合格品率。
* 调查50个人，50个人中患色盲的人数Y服从二项分布b(50,p),其中p为色盲率。
* 射击5次，5次都命中的概率服从二项分布b(5,p)，其中p为射手的命中率。

二项分布的数学期望和方差如下：
* $E(x)=np,E(x^2) =n(n-1)p^2+np$
* $Var(X)=E(X^2)-E((X))^2=np(1-p)$

### 二点分布
n = 1时的二项分布b(1,p)称为**二点分布**，或者**0~1分布**，或者称**伯努利分布**。其分布列为：
$$
P(X=x)=p^x(1-p)^{1-x} , x = 0,1
$$
两点分布一般用来描述一次伯努利实验中的成功（记为A）的次数（0或1）。
很多随机现象的样本空间$\Omega$常可以一分为二，记作$A$与$\overline{A}$，也就是伯努利试验。n重伯努利实验是由n次相同且独立的伯努利试验组成，那么也就是n个相同的两点分布之和。这就是二项分布和二点分布的联系。

### 泊松分布及其二项近似 
泊松分布是由法国数学家泊松首次提出的，它的概率分布列是：
$$
P(X=k)=\frac{\lambda^k}{k!}e^{-\lambda},k = 0,1,2,...
其中参数\lambda > 0，记为X \sim P(\lambda)
$$


### 超几何分布及其二项近似


### 几何分布与负二项分布


## 2.5 常用连续分布
### 正态分布（高斯分布）

### 均匀分布

### 指数分布

### 伽马分布

### 贝塔分布

## 常用分布的数学期望及方差

## 2.6 随机变量函数的分布
### 离散随机变量函数的分布

### 连续随机变量函数的分布


## 2.7 分布的其他特征数
### k阶矩

### 变异系数

### 分位数

### 中位数

### 偏度系数

### 峰度系数


# 第三 多维随机变量及其分布
## 3.1 多维变量及其联合分布
### 多维随机变量的基本概念

### 联合分布函数和联合分布列

### 联合密度函数

### 常见多维分布


## 3.2 边际分布与随机变量的独立性
### 边际分布函数和边际分布列

### 边际密度函数

### 随机变量间的独立性


## 3.3 多维随机变量函数的分布 
### 多维离散随机变量函数的分布

### 最大值与最小值的分布

### 连续场合的卷积公式

### 变量变换法


## 3.4 多维随机变量的特征数
### 数学期望

### 方差

### 协方差

### 随机向量的数学期望向量与协方差矩阵

## 3.5 条件分布与条件期望
### 条件分布

### 条件数学期望

# 第四 大数定律与中心极限定理
## 4.1 随机变量序列的两种收敛性

### 依概率收敛

### 按分布收敛/弱收敛


## 4.2 特征函数
### 基本概念，性质

### 常用分布的特征函数

### 特征函数唯一决定分布函数


## 4.3 大数定律
### 伯努利大数定律

### 常用的几个大数定律（一般形式，切比雪夫，马尔可夫，辛钦）


## 4.4 中心极限定理
### 独立随机变量和

### 独立同分布下的中心极限定理

### 二项分布的正态近似

### 独立不同分布下的中心极限定理
